

# **An Architectural Analysis of the InstaVibe Multi-Agent System**

## **Introduction to the InstaVibe Architecture**

The InstaVibe project, as detailed in its associated Google Codelab, presents a sophisticated blueprint for an AI-powered social planning platform. It addresses the significant user friction associated with organizing group activities by employing a system of intelligent, autonomous agents. The core vision is to transform social planning from a logistical chore into a "seamless and delightful experience" by automating tasks such as discovering shared interests among friends, researching tailored activities, and coordinating initial plans.1 The project serves as a practical, in-depth exploration of constructing a production-grade multi-agent system using a modern, cloud-native technology stack.

### **The Multi-Agent System (MAS) Paradigm**

At the heart of the InstaVibe prototype is a multi-agent system (MAS), an architectural choice that favors decentralization and specialization over a single, monolithic AI model. This system is composed of four distinct agents, each with a specialized function, that collaborate to achieve a complex goal.1 This design paradigm offers substantial benefits in terms of modularity, scalability, and maintainability. The roles are clearly delineated:

* **Orchestrator Agent:** This agent functions as the central coordinator or "brain" of the operation. It receives the initial high-level request from a user (e.g., "plan a fun weekend for my friends and me"), decomposes the goal into a logical sequence of sub-tasks, and delegates these tasks to the appropriate specialist agents.1  
* **Social Profiling Agent:** This agent is the system's data analyst. It is responsible for social listening, analyzing user connections, interactions, and public data to identify shared interests and suitable activity characteristics for a given group of friends.1  
* **Event Planning Agent:** Acting as the system's researcher, this agent takes the insights generated by the Social Profiling Agent and searches external online resources for specific events, venues, or creative ideas that align with the group's identified preferences.1  
* **Platform Interaction Agent:** This agent serves as the bridge between the AI system and the core InstaVibe application. Its sole function is to interact with the platform's backend services to perform concrete actions, such as drafting an event suggestion or creating a post for users to view.1

### **Core Enabling Technologies: A Triad of Frameworks and Protocols**

The functionality of the InstaVibe MAS is enabled by a carefully selected triad of frameworks, protocols, and cloud infrastructure, which together provide a comprehensive solution for building, deploying, and scaling agentic applications.

* **Google's Agent Development Kit (ADK):** The ADK is the foundational software development kit used to construct each agent. It provides the essential components for defining an agent's core logic, instructions, behavior, and state management. The ADK also includes built-in tools for managing the agent lifecycle, memory, and integration with external capabilities, serving as the primary scaffolding for agent creation.1  
* **Agent-to-Agent (A2A) Communication Protocol:** A2A is a critical open standard that defines how autonomous, intelligent agents discover and collaborate with one another. It provides a standardized "language of collaboration," allowing agents to delegate complex, high-level tasks that require reasoning and intelligence from the receiving agent. This protocol is fundamental to the orchestration pattern employed by InstaVibe.1  
* **Model Context Protocol (MCP):** Complementing A2A, MCP is an open standard designed to connect agents with non-sentient external systems, such as APIs, databases, or other tools. While A2A facilitates peer-to-peer collaboration, MCP provides a standardized "interface to the outside world," enabling agents to execute specific, deterministic actions by calling predefined functions.1  
* **Google Cloud Platform (GCP):** The entire system is built to run on GCP, leveraging a suite of managed services that provide the necessary infrastructure for a scalable, production-ready application. Key services include **Vertex AI**, which supplies the powerful Gemini family of Large Language Models (LLMs) for agent reasoning and the **Vertex AI Agent Engine** for deploying and managing the Orchestrator agent; **Cloud Run**, a serverless platform used to host the specialist agents as independent microservices; and **Spanner**, a globally distributed relational database uniquely leveraged for its graph database capabilities to model and query complex social relationships.1

The architectural decision to employ both A2A and MCP protocols is not a redundancy but a highly deliberate and sophisticated design choice. A less mature system might rely on simple REST API calls for all inter-service communication, which would problematically blur the distinction between an intelligent collaborator and a simple, functional tool. This approach would lead to tight coupling and a brittle architecture where any change in one agent's API could cascade and break its dependents.

The InstaVibe architecture avoids this pitfall by establishing a clear and powerful taxonomy of interactions. It uses the A2A protocol for delegating high-level, cognitive tasks. For instance, when the Orchestrator asks the Social Profiling Agent to "analyze the shared interests of these users," it is invoking a peer that possesses its own reasoning capabilities to interpret the request and formulate a complex response.4 In contrast, the system uses the MCP protocol for commanding low-level, deterministic actions. When the Platform Interaction Agent is instructed to "create a post with this specific text," it is using an MCP client to call a simple tool exposed by an MCP server, which acts merely as an API gateway without any intelligence of its own.8 This explicit separation makes the system profoundly more modular and resilient. Agents (A2A peers) and tools (MCP services) can be developed, tested, deployed, and replaced independently, fostering a robust and scalable architecture designed for long-term evolution.

## **Macrostructure of the instavibe-bootstrap Repository**

The instavibe-bootstrap repository is organized with a deliberate, modular structure that reflects a modern, service-oriented architectural philosophy. This layout is not merely a convenience for the Codelab but serves as a prescriptive blueprint for building, managing, and deploying complex, production-grade multi-agent systems. The top-level directory structure clearly separates distinct components of the application, promoting clean boundaries and independent development lifecycles.1

### **A Modular, Service-Oriented Layout**

The key directories at the root of the repository are:

* agents/: This directory is the functional heart of the AI system. It contains the complete source code for each of the four intelligent agents, with each agent housed in its own dedicated subdirectory. This modular organization embodies the multi-agent paradigm of the architecture.1  
* instavibe/: This directory contains the entire source code for the InstaVibe web application. The strict separation of the user-facing front-end from the AI-powered back-end is a critical design choice that allows for independent development, testing, and deployment of the user interface.1  
* tools/: This directory is designated for external tools that the agents can utilize. Specifically, it contains the implementation of the Model Context Protocol (MCP) Server, which exposes the core InstaVibe platform's internal APIs in a standardized way for agent consumption.1  
* utils/, init.sh, set\_env.sh: These files provide utility scripts for project initialization and environment variable configuration, streamlining the setup process for developers.1

This repository structure is a direct reflection of a microservices architecture, a pattern that is essential for building scalable and maintainable systems. The clear separation of concerns between the agents/, instavibe/, and tools/ directories allows different development teams to work in parallel. For example, a front-end team can iterate on the user interface within the instavibe/ directory, a platform engineering team can manage the core APIs and their exposure via the MCP server in the tools/ directory, and multiple AI engineering teams could potentially own and develop different agents within the agents/ directory.

Furthermore, the design promotes decoupling and resilience. The tools/ directory, containing the MCP server, acts as an anti-corruption layer. It creates a stable, standardized interface (the MCP API) that the agents can rely on. This means the internal InstaVibe platform API can be refactored or changed without immediately breaking the agents, as long as the contract exposed by the MCP server remains consistent. Each agent's subdirectory within agents/ contains its own Dockerfile, reinforcing the concept that each agent is a distinct, containerized, and independently deployable unit.1 This architectural purity is what elevates the project from a simple academic exercise to a robust template for real-world agentic systems.

## **The agents Directory: Anatomy of a Collaborative AI System**

The agents/ directory is the epicenter of the InstaVibe project's artificial intelligence capabilities. It houses the source code for the four specialized agents that form the collaborative system. The internal structure of this directory is highly standardized, with each agent's subdirectory following a consistent and repeatable pattern that separates its core logic, communication interface, and deployment configuration.

### **The Standardized Agent Structure**

Within each subdirectory inside agents/ (e.g., planner/, social/), a consistent set of three key files defines the agent's existence:

* agent.py: This file represents the core logic and "mind" of the agent. It is here that the agent is defined using the Google Agent Development Kit (ADK). This script specifies the agent's high-level instructions, configures the underlying Large Language Model (e.g., Google's Gemini models), and defines any tools the agent can use to interact with its environment or external services.1  
* a2a\_server.py: This file serves as the agent's communication layer. It takes the ADK agent object defined in agent.py and wraps it in a web server that is compliant with the Agent-to-Agent (A2A) communication protocol. Using the a2a-python library, this script is responsible for exposing the agent as a network service, handling incoming task requests from other agents, and publishing the agent's "Agent Card"—a machine-readable description of its capabilities—for service discovery.1  
* Dockerfile: This file is the deployment manifest for the agent. It contains a set of instructions for building a standardized, portable container image. This process involves setting up the necessary operating system and runtime environment (e.g., Python), installing dependencies, copying the agent's source code (agent.py, a2a\_server.py), and specifying the command to start the A2A server. This containerization allows each agent to be deployed as an independent microservice on platforms like Google Cloud Run.1

### **System Overview Table**

To provide a clear, high-level understanding of the entire agent ecosystem before delving into the specifics of each component, the following table summarizes the role, communication protocols, and deployment environment for each agent. This overview serves as a quick reference to the system's architecture, clarifying how the individual pieces fit together to form a cohesive whole.

| Agent Directory | Primary Function | Key Protocols Utilized | Deployment Target |
| :---- | :---- | :---- | :---- |
| orchestrate/ | Manages workflow and delegates tasks to other agents. Acts as the central "brain" of the operation. | A2A Client | Vertex AI Agent Engine |
| planner/ | Searches online resources for events, venues, and ideas that align with user interests. | A2A Server, External Tooling (e.g., Search) | Google Cloud Run |
| social/ | Analyzes user connections, interactions, and public trends from the Spanner database to identify shared interests. | A2A Server | Google Cloud Run |
| platform\_mcp\_client/ | Interacts directly with the InstaVibe platform's backend API to draft and create posts. | A2A Server, MCP Client | Google Cloud Run |

This table immediately highlights the architectural patterns at play. The Orchestrator is unique in its primary role as an A2A Client and its deployment to the specialized Agent Engine service. The other three agents are all A2A Servers, deployed as scalable microservices on Cloud Run, each providing a distinct "skill" to the network. The Platform Interaction agent is further distinguished by its dual-protocol nature, acting as both an A2A server and an MCP client. This structured overview provides the necessary context for a deeper, file-level analysis of each agent.

## **Analysis of the Orchestrator Agent (agents/orchestrate/)**

The Orchestrator Agent is the linchpin of the InstaVibe multi-agent system. It embodies the "plan-and-execute" pattern, acting as the central coordinator that directs the workflow and delegates tasks to the specialized worker agents. Its primary responsibility is not to perform tasks itself, but to understand the user's high-level goal and manage the flow of information between the other agents to achieve it.1

### **agent.py: The Logic of Delegation**

The agent.py file for the Orchestrator defines its core coordinating logic using the Agent Development Kit. Unlike the other agents, which are typically defined as a single LlmAgent, the Orchestrator is likely implemented using one of ADK's workflow agents, such as LoopAgent or a sequential agent, which are designed to manage multi-step processes involving sub-agents.1

The instruction set provided to the Orchestrator's LLM is focused on goal decomposition. When given a user request like "plan an event for me and my friends," its primary function is to break this down into a logical sequence:

1. First, analyze the social profiles of the user and their friends to find common interests.  
2. Next, use these interests to search for suitable event ideas.  
3. Finally, take the best event idea and draft a post on the InstaVibe platform.1

The "tools" available to the Orchestrator are not for interacting with the outside world directly, but for communicating with its peers. These tools are A2A clients. The agent's initialization logic would involve fetching the AgentCard from each of the specialist agents (Planner, Social, Platform Interaction) to dynamically discover their capabilities and endpoints.4 The core logic of the agent then involves managing the state and data flow, ensuring the output from one agent (e.g., the JSON summary of shared interests from the Social agent) is correctly formatted and passed as input to the next agent in the chain (e.g., the Planner agent).1

### **a2a\_server.py: The Entry Point**

While the Orchestrator's primary function within the multi-agent system is that of an A2A *client* (it calls other agents), it must also expose itself as an A2A *server*. The a2a\_server.py file accomplishes this by wrapping the core agent logic in an A2A-compliant web server.1 This server acts as the main entry point for the entire workflow. The InstaVibe web application initiates the process by making a single A2A call to the Orchestrator agent, which then kicks off the entire chain of delegated tasks.1

### **Dockerfile: Packaging for a Managed Service**

The Dockerfile for the Orchestrator packages the agent and its dependencies into a container image for deployment. The Codelab specifies a distinct deployment target for this agent: **Vertex AI Agent Engine**.1 This is a strategic choice. Agent Engine is a fully managed Google Cloud service specifically designed to host, scale, and manage complex, potentially long-running, and stateful agentic workflows. By deploying the Orchestrator to Agent Engine, developers can abstract away the complexities of infrastructure management, scaling, and observability, allowing them to focus on the orchestration logic itself. The Dockerfile will contain the necessary configurations to be compatible with this managed environment.1

## **Analysis of the Event Planning Agent (agents/planner/)**

The Event Planning Agent, or Planner, serves as the creative and research-oriented component of the InstaVibe system. Its specific function is to take a set of criteria—such as location, dates, and a summary of user interests—and generate concrete, actionable event suggestions by searching external resources.

### **agent.py: Logic for Discovery and Planning**

The agent.py file for the Planner defines a core LlmAgent using the ADK. The natural language instructions provided to this agent are crucial; they guide the LLM to be a creative event planner. The instructions will prompt the agent to generate fun, tailored suggestions and, importantly, to structure its final output in a consistent format, such as JSON, to ensure it can be programmatically parsed by the Orchestrator.15

To perform its function, the Planner agent is equipped with tools that allow it to access real-world, up-to-date information. These tools are not other agents but direct integrations with external APIs, such as a Google Search tool for finding articles and listings, or a Google Maps API tool for identifying venues and locations.2 The agent's logic leverages the LLM's advanced function-calling capabilities. When presented with a task, the LLM determines which tool to use, formulates the necessary query, and then synthesizes the information returned by the tool into a coherent and well-structured event plan.16

### **a2a\_server.py: Exposing Planning as a Service**

The a2a\_server.py script is responsible for transforming the Planner agent from a standalone piece of logic into a discoverable network service. It wraps the ADK agent in an A2A server and, most critically, defines and publishes its AgentCard.4

The Agent Card is the agent's digital business card and is fundamental to the A2A discovery process. The code in this file will explicitly define the card's contents, including:

* A unique skill ID (e.g., event\_planner).  
* A human-readable name and description (e.g., "Event Planner Agent," "This agent generates fun plan suggestions...").  
* The public URL of the running service.  
* A schema defining the expected inputs (location, interests) and outputs (a structured plan).

This card is hosted at a standardized endpoint, allowing the Orchestrator to fetch it, understand the Planner's capabilities, and learn how to correctly invoke its service without any hardcoded configuration.4

### **Dockerfile: Containerization for Cloud Run**

The Dockerfile for the Planner agent contains the instructions to package it into a self-contained, executable container image. The file specifies the base Python image, copies the source code (agent.py, a2a\_server.py) and any other dependencies into the image, installs the required Python packages, and sets the entry point command to run the a2a\_server.py script.15

This container is designed for deployment as an independent microservice on **Google Cloud Run**. This serverless platform is an ideal choice for the Planner agent because it is a stateless, single-purpose service. Cloud Run automatically handles scaling, so if many users are planning events simultaneously, it can scale up the number of Planner agent instances to handle the load and scale back down to zero when not in use, providing a cost-effective and efficient hosting solution.1

## **Analysis of the Social Profiling Agent (agents/social/)**

The Social Profiling Agent acts as the data-centric intelligence of the InstaVibe system. Its role is to analyze the application's underlying data to extract meaningful insights about users and their relationships. This foundational analysis provides the context necessary for generating truly personalized event suggestions.

### **agent.py: Logic for Data Analysis**

The core logic of the Social Profiling Agent, defined in agent.py, is centered around its ability to interact with the application's primary database. The InstaVibe architecture leverages **Spanner** not just as a standard relational database but specifically for its capabilities as a Graph Database, which is exceptionally well-suited for modeling and querying complex social networks of users, friendships, and interactions.1

The agent.py file configures an ADK agent with instructions for the LLM to act as a social data analyst. The agent is equipped with a custom tool that can execute queries against the Spanner database. The LLM's task is to translate a natural language request from the Orchestrator (e.g., "Find shared interests for users A, B, and C") into a formal query—likely a Graph query or a specialized SQL statement—that can be executed by its tool. The agent then processes the query results and synthesizes them into a concise summary to be returned to the Orchestrator.1

### **a2a\_server.py: Exposing Social Insights as a Service**

Similar to the Planner, the a2a\_server.py script for the Social agent wraps the core ADK agent in an A2A-compliant server. It is responsible for creating and publishing the agent's AgentCard, which advertises its specialized skill in social profile analysis.15 The Orchestrator discovers the Social agent by fetching this card and uses the defined A2A interface to delegate the initial data-gathering task. This service-oriented approach cleanly encapsulates the logic for social data analysis, making it a reusable component within the broader system.

### **Dockerfile: Packaging the Data-Centric Agent**

The Dockerfile for the Social agent packages its code and dependencies into a container for deployment.22 While structurally similar to the Planner's Dockerfile, it would include any additional libraries or configuration required for connecting to the Spanner database. This might involve setting up environment variables for the database instance and project ID, and ensuring that the container has the necessary authentication credentials (typically handled via GCP service accounts) to securely access the data.

Like the Planner, the Social Profiling Agent is deployed as a standalone microservice on **Google Cloud Run**.1 This deployment strategy effectively isolates the data access logic. If the database schema changes or the querying logic needs to be optimized, the Social agent can be updated and redeployed independently without affecting any other part of the multi-agent system.

## **Analysis of the Platform Interaction Agent (agents/platform\_mcp\_client/)**

The Platform Interaction Agent serves a unique and critical role as the final link in the orchestration chain. It acts as the bridge between the abstract planning world of the AI agents and the concrete reality of the InstaVibe application. Its sole purpose is to execute specific actions on the platform, such as creating a post, using the finalized plan provided by the Orchestrator. This agent is a prime example of a dual-protocol component, operating as both an A2A server and an MCP client.

### **agent.py: The MCP Client Logic**

The agent.py file for this agent defines its function as a **Model Context Protocol (MCP) Client**. This is where the agent is given the ability to use external, non-sentient tools that are exposed by the InstaVibe platform's backend.1

The agent's configuration within the ADK involves equipping it with an MCPToolset.24 This toolset is configured with the URL of the separate MCP Server (located in the

tools/ directory). Upon initialization, the agent connects to this server and dynamically discovers the available tools, such as create\_post or draft\_event, by fetching the tool list from the server's list\_tools endpoint.8 The agent's instructions are straightforward: take a finalized plan as input and use the provided MCP tools to execute the necessary actions on the platform. The LLM's role is to correctly map the data from the plan to the arguments required by the MCP tool's schema and then invoke it.1 Evidence from a GitHub issue traceback for this specific project confirms the use of an

LlmAgent being initialized with an MCPToolset in this file, validating this architectural approach.24

### **a2a\_server.py: A Dual-Protocol Role**

While the agent *acts* as an MCP client, it is *called* by the Orchestrator via the A2A protocol. Therefore, the a2a\_server.py file is essential for this agent to function within the system.25 It wraps the agent in an A2A server, allowing it to receive high-level tasks from the Orchestrator (e.g., "Post this plan to the platform"). This creates a sophisticated architectural pattern: the agent receives its high-level goal via A2A and then uses MCP to execute the low-level, mechanical steps required to achieve that goal. This separation of concerns is a hallmark of a well-designed agentic system.

### **Dockerfile: Deploying the Bridge**

The Dockerfile packages the Platform Interaction Agent into a container for deployment on **Google Cloud Run**.27 This deployment strategy is highly advantageous because it isolates the logic that is tightly coupled to the InstaVibe platform's internal API. If the platform's API undergoes changes, only this single, dedicated microservice needs to be updated. The Orchestrator and other agents remain unaffected because they only interact with the stable A2A interface of the Platform Interaction Agent. This encapsulation significantly improves the maintainability and evolvability of the entire system.

## **Deconstruction of Communication and Tooling Protocols**

The InstaVibe architecture's effectiveness hinges on its principled use of two distinct open standards for communication: the Agent-to-Agent (A2A) protocol for collaboration between intelligent peers, and the Model Context Protocol (MCP) for interaction with external tools. A detailed examination of their practical implementation reveals a robust, dynamic, and decoupled system design.

### **A2A in Practice: The a2a-python Library and Agent Cards**

The collaboration between the Orchestrator and the specialist agents is orchestrated entirely through the A2A protocol, facilitated by the a2a-python library. The communication flow follows a standardized and dynamic pattern:

1. **Service Exposure:** Each specialist agent (Planner, Social, Platform Interaction) uses the library to start an A2AStarletteApplication. This instantly transforms the agent's logic into a network-accessible service.4  
2. **Discovery via Agent Cards:** The A2A server automatically hosts a machine-readable AgentCard at a standardized, well-known endpoint: /.well-known/agent.json.5 This card contains vital metadata about the agent, including its name, description, capabilities, and the schema for its skills.4  
3. **Dynamic Onboarding:** Upon its initialization, the Orchestrator, acting as an A2A client, fetches these Agent Cards from the known URLs of the specialist agents. This process is how the Orchestrator "meets the team" and learns programmatically what skills are available across the network and how to invoke them.4  
4. **Task Delegation:** When the Orchestrator needs to delegate a task, it constructs a standardized JSON-RPC 2.0 message containing the task details and sends it via an HTTP POST request to the target agent's endpoint.18

This service-discovery-based approach is far more resilient and flexible than hardcoding agent endpoints and capabilities. It allows new specialist agents to be added to the system, or existing ones to be updated, with the Orchestrator able to adapt to these changes dynamically simply by re-reading their Agent Cards.

### **MCP in Practice: The tools/instavibe/ MCP Server**

The interaction between the Platform Interaction Agent and the core InstaVibe application is mediated by the MCP protocol. The implementation is cleanly separated into the tools/instavibe/ directory, which contains the MCP Server.1 This server is a lightweight web application, likely built with a framework like FastAPI, that acts as a standardized wrapper or gateway for the platform's internal REST API.8

The MCP server adheres to the protocol standard by exposing two fundamental endpoints:

* list\_tools(): When an MCP client (the Platform Interaction Agent) connects, it first calls this endpoint. The server responds with a machine-readable JSON object that lists all available tools (e.g., create\_post), provides natural language descriptions for each, and includes a detailed JSON Schema for their required arguments. This schema is critical, as it allows the agent's LLM to understand precisely how to format its function calls, drastically reducing errors.8  
* call\_tool(name, arguments): After the agent's LLM decides which tool to use, it invokes this endpoint, providing the tool's name and a dictionary of arguments that conform to the previously discovered schema. The MCP server receives this request, routes it to the corresponding internal Python function which handles the logic of making the actual call to the InstaVibe platform's API, and returns the result.8

This architecture masterfully decouples the agent's reasoning process from the messy implementation details of API calls, such as handling HTTP headers, authentication, and endpoint URLs. The agent only needs to know about the abstract create\_post tool, not the underlying mechanics of the platform's API, which is a powerful principle for building maintainable and robust AI systems.

## **Conclusion: Architectural Insights and Design Patterns**

The architectural design of the InstaVibe multi-agent system, as manifested in the instavibe-bootstrap repository, provides a comprehensive and practical guide to building sophisticated, collaborative AI applications. The project moves beyond theoretical concepts to demonstrate a series of powerful, production-oriented design patterns that are critical for developing scalable, resilient, and maintainable systems.

### **The Orchestrator-Worker Pattern Revisited**

The entire system is a quintessential example of the **Orchestrator-Worker** pattern, also known as "plan-and-execute." The Orchestrator agent is responsible for the high-level planning and reasoning—decomposing a complex user goal into a sequence of manageable steps. The specialized worker agents (Planner, Social, Platform Interaction) are then responsible for executing these individual steps.16 This separation of concerns is a foundational pattern in modern agentic systems. It allows the planner to be a powerful, generalist LLM, while the workers can be smaller, more focused agents or tools, leading to greater efficiency, lower costs, and improved performance on specialized tasks.

### **Microservices and Decentralization as a Core Tenet**

A core tenet of the InstaVibe architecture is its deep commitment to decentralization through a **microservices-based approach**. By containerizing each agent with its own Dockerfile and deploying it as an independent, network-addressable service on platforms like Cloud Run and Agent Engine, the system gains immense architectural benefits. This modularity ensures that the agents are loosely coupled. A bug, update, or failure in the Event Planning agent, for instance, will not cause a cascading failure that brings down the Social Profiling agent or the Orchestrator. This resilience is paramount in production environments. Furthermore, it allows for independent scaling; if social profiling becomes a bottleneck, only that specific service needs to be scaled up. This approach also facilitates parallel development, as different teams can own and iterate on different agent-microservices without interfering with one another.

### **A Practical Blueprint for Complex AI Systems**

Ultimately, the InstaVibe Codelab and its accompanying instavibe-bootstrap repository should be viewed not merely as an instructional tutorial, but as a holistic, production-oriented **blueprint for complex AI systems**. It demonstrates with concrete code and infrastructure choices how to effectively combine a foundational agent framework (Google's ADK), a clear taxonomy of communication protocols (A2A for peer collaboration and MCP for tool use), and a scalable, serverless cloud infrastructure (GCP). The project provides a clear path for developers and architects to move from simple, single-agent chatbots to sophisticated, multi-agent systems capable of solving tangible, real-world problems. The design patterns and principles embedded within its structure represent a mature and forward-looking approach to the burgeoning field of agentic software engineering.

#### **Works cited**

1. Google's Agent Stack in Action: ADK, A2A, MCP on Google Cloud \- Codelabs, accessed September 14, 2025, [https://codelabs.developers.google.com/instavibe-adk-multi-agents/instructions](https://codelabs.developers.google.com/instavibe-adk-multi-agents/instructions)  
2. InstaVibe: Multi-Agent AI System on Google Cloud \- GitHub, accessed September 14, 2025, [https://github.com/shlok695/instavibe\_agent](https://github.com/shlok695/instavibe_agent)  
3. A collection of sample agents built with Agent Development (ADK) \- GitHub, accessed September 14, 2025, [https://github.com/google/adk-samples](https://github.com/google/adk-samples)  
4. How My AI Agents Learned to Talk to Each Other With A2A \- DZone, accessed September 14, 2025, [https://dzone.com/articles/multi-agent-ai-architecture-a2a-protocol](https://dzone.com/articles/multi-agent-ai-architecture-a2a-protocol)  
5. Getting Started with Agent2Agent (A2A) Protocol: A Purchasing Concierge and Remote Seller Agent Interactions with Gemini on Cloud Run and Agent Engine \- Codelabs, accessed September 14, 2025, [https://codelabs.developers.google.com/intro-a2a-purchasing-concierge](https://codelabs.developers.google.com/intro-a2a-purchasing-concierge)  
6. mcp-agent · GitHub Topics, accessed September 14, 2025, [https://github.com/topics/mcp-agent](https://github.com/topics/mcp-agent)  
7. lastmile-ai/mcp-agent: Build effective agents using Model Context Protocol and simple workflow patterns \- GitHub, accessed September 14, 2025, [https://github.com/lastmile-ai/mcp-agent](https://github.com/lastmile-ai/mcp-agent)  
8. Stop Prompt Hacking: How I Connected My AI Agent to Any API With MCP \- DZone, accessed September 14, 2025, [https://dzone.com/articles/ai-agents-api-integration-with-mcp](https://dzone.com/articles/ai-agents-api-integration-with-mcp)  
9. Building AI agents made easy with Goose and Docker, accessed September 14, 2025, [https://www.docker.com/blog/building-ai-agents-with-goose-and-docker/](https://www.docker.com/blog/building-ai-agents-with-goose-and-docker/)  
10. Orchestrate multiple AI agents with cagent by Docker to create a BC/AL coding assistant, accessed September 14, 2025, [https://tobiasfenster.io/orchestrate-multiple-ai-agents-with-cagent-by-docker](https://tobiasfenster.io/orchestrate-multiple-ai-agents-with-cagent-by-docker)  
11. Run a self-hosted agent in Docker \- Azure Pipelines | Microsoft Learn, accessed September 14, 2025, [https://learn.microsoft.com/en-us/azure/devops/pipelines/agents/docker?view=azure-devops](https://learn.microsoft.com/en-us/azure/devops/pipelines/agents/docker?view=azure-devops)  
12. Docker brings agent orchestration into your microservices workflow \- AI Native Dev, accessed September 14, 2025, [https://ainativedev.io/news/docker-brings-agent-orchestration-into-your-microservices-workflow](https://ainativedev.io/news/docker-brings-agent-orchestration-into-your-microservices-workflow)  
13. Introducing the Beta Launch of Docker's AI Agent, Transforming Development Experiences, accessed September 14, 2025, [https://www.docker.com/blog/beta-launch-docker-ai-agent/](https://www.docker.com/blog/beta-launch-docker-ai-agent/)  
14. ADK Dev UI \- Graph error · Issue \#1170 · google/adk-python \- GitHub, accessed September 14, 2025, [https://github.com/google/adk-python/issues/1170](https://github.com/google/adk-python/issues/1170)  
15. Pile d'agents Google en action : ADK, A2A, MCP sur Google Cloud \- Codelabs, accessed September 14, 2025, [https://codelabs.developers.google.com/instavibe-adk-multi-agents/instructions?hl=fr](https://codelabs.developers.google.com/instavibe-adk-multi-agents/instructions?hl=fr)  
16. Plan-and-Execute Agents \- LangChain Blog, accessed September 14, 2025, [https://blog.langchain.com/planning-agents/](https://blog.langchain.com/planning-agents/)  
17. Building Multi-Agent AI App with Google's A2A (Agent2Agent) Protocol, ADK, and MCP \- A Deep Dive \- Medium, accessed September 14, 2025, [https://medium.com/ai-cloud-lab/building-multi-agent-ai-app-with-googles-a2a-agent2agent-protocol-adk-and-mcp-a-deep-a94de2237200](https://medium.com/ai-cloud-lab/building-multi-agent-ai-app-with-googles-a2a-agent2agent-protocol-adk-and-mcp-a-deep-a94de2237200)  
18. How to Build Two Python Agents with Google's A2A Protocol \- Step by Step Tutorial, accessed September 14, 2025, [https://docs.kanaries.net/articles/build-agent-with-a2a](https://docs.kanaries.net/articles/build-agent-with-a2a)  
19. Docker Brings Compose to the Agent Era: Building AI Agents is Now Easy, accessed September 14, 2025, [https://www.docker.com/blog/build-ai-agents-with-docker-compose/](https://www.docker.com/blog/build-ai-agents-with-docker-compose/)  
20. Complete Guide to Build and Deploy an AI Agent with Docker Containers and Python, accessed September 14, 2025, [https://www.youtube.com/watch?v=KC8HT0eWSGk](https://www.youtube.com/watch?v=KC8HT0eWSGk)  
21. Building an Agent-to-Agent (A2A) Communication System in Python | by Jay Kim | Medium, accessed September 14, 2025, [https://medium.com/@bravekjh/building-an-agent-to-agent-a2a-communication-system-in-python-59ab3d125b90](https://medium.com/@bravekjh/building-an-agent-to-agent-a2a-communication-system-in-python-59ab3d125b90)  
22. webdevops/bootstrap \- Dockerfile Documentation \- Read the Docs, accessed September 14, 2025, [https://dockerfile.readthedocs.io/en/latest/content/DockerImages/dockerfiles/bootstrap.html](https://dockerfile.readthedocs.io/en/latest/content/DockerImages/dockerfiles/bootstrap.html)  
23. Definition Files — Singularity container 3.5 documentation, accessed September 14, 2025, [https://docs.sylabs.io/guides/3.5/user-guide/definition\_files.html](https://docs.sylabs.io/guides/3.5/user-guide/definition_files.html)  
24. ADK with Notion MCP · Issue \#881 · google/adk-python \- GitHub, accessed September 14, 2025, [https://github.com/google/adk-python/issues/881](https://github.com/google/adk-python/issues/881)  
25. Agent2Agent (A2A) Protocol \- Pydantic AI, accessed September 14, 2025, [https://ai.pydantic.dev/a2a/](https://ai.pydantic.dev/a2a/)  
26. a2a-mcp-server 0.1.2 on PyPI \- Libraries.io, accessed September 14, 2025, [https://libraries.io/pypi/a2a-mcp-server](https://libraries.io/pypi/a2a-mcp-server)  
27. Make AI apps easily and securely with MCP and Models on Docker | DEMFP793 \- YouTube, accessed September 14, 2025, [https://www.youtube.com/watch?v=YJ4w6Go4ZiQ](https://www.youtube.com/watch?v=YJ4w6Go4ZiQ)  
28. These New Docker AI Features Change Everything \- YouTube, accessed September 14, 2025, [https://www.youtube.com/watch?v=7XIv3Bko1aA](https://www.youtube.com/watch?v=7XIv3Bko1aA)  
29. Getting Started with Quarkus and the A2A Java SDK, accessed September 14, 2025, [https://quarkus.io/blog/quarkus-and-a2a-java-sdk/](https://quarkus.io/blog/quarkus-and-a2a-java-sdk/)